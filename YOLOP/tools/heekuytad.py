import argparse
import os, sys
import time
import torch
import cv2
import numpy as np
import torchvision.transforms as transforms
import pyzed.sl as sl
import torch.nn.functional as F

# Import YOLOP utilities
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from lib.config import cfg
from lib.models import get_net
from lib.core.general import non_max_suppression
from lib.utils import plot_one_box, show_seg_result
from lib.core.general import scale_coords

# Normalize for YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ----------------- ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i -----------------
zed = sl.Camera()
init_params = sl.InitParameters()
init_params.camera_resolution = sl.RESOLUTION.HD720  
init_params.camera_fps = 60
init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE  # ‡πÉ‡∏ä‡πâ Depth Mode
init_params.coordinate_units = sl.UNIT.METER  # ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£

if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    exit()

image = sl.Mat()
depth_map = sl.Mat()

# ----------------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOP -----------------
def load_yolop_model(weights_path, device):
    model = get_net(cfg)
    checkpoint = torch.load(weights_path, map_location=device)
    model.load_state_dict(checkpoint['state_dict'])
    model = model.to(device)
    model.eval()
    print(f"‚úÖ Model Loaded: {weights_path}")
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ Using device: {device}")
model = load_yolop_model("/home/mag/satoi/python/YOLOP/weights/End-to-end.pth", device)

# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Depth ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ -----------------
def get_depth_for_detections(depth_map, detections):
    """
    ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∂‡∏Å (Depth) ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å Bounding Box
    """
    object_depths = []
    
    if detections is None or len(detections) == 0:
        return object_depths  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏

    for det in detections:
        x1, y1, x2, y2 = map(int, det[:4])  # ‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î Bounding Box

        # ‡∏ï‡∏±‡∏î ROI ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Bounding Box
        obj_depth_roi = depth_map[y1:y2, x1:x2]

        # ‡∏•‡∏ö‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô NaN ‡∏´‡∏£‡∏∑‡∏≠ Inf ‡∏≠‡∏≠‡∏Å
        valid_depth = obj_depth_roi[np.isfinite(obj_depth_roi)]

        if len(valid_depth) == 0:
            object_depths.append(None)  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
        else:
            object_depths.append(np.median(valid_depth))  # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤ median ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏•‡∏î Noise
    
    return object_depths

# ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡πÅ‡∏•‡∏∞ Lane -----------------
def detect_obstacles(image, model):
    input_image = transform(image).to(device)
    input_image = input_image.unsqueeze(0)

    with torch.no_grad():
        det_out, da_seg_out, ll_seg_out = model(input_image)

    _, _, height, width = input_image.shape
    da_seg_out = F.interpolate(da_seg_out, size=(height, width), mode='bilinear', align_corners=False)
    ll_seg_out = F.interpolate(ll_seg_out, size=(height, width), mode='bilinear', align_corners=False)

    da_seg_mask = torch.max(da_seg_out, 1)[1].squeeze().cpu().numpy()
    ll_seg_mask = torch.max(ll_seg_out, 1)[1].squeeze().cpu().numpy()

    # ‡πÉ‡∏ä‡πâ non_max_suppression ‡∏Å‡∏±‡∏ö det_out
    det_pred = non_max_suppression(det_out[0], conf_thres=0.25, iou_thres=0.45)

    return da_seg_mask, ll_seg_mask, det_pred

# ----------------- ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö -----------------
while True:
    if zed.grab() == sl.ERROR_CODE.SUCCESS:
        zed.retrieve_image(image, sl.VIEW.LEFT)
        zed.retrieve_measure(depth_map, sl.MEASURE.DEPTH)

        frame = image.get_data()[:, :, :3]  
        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)  

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡πÅ‡∏•‡∏∞ Lane
        da_seg_mask, ll_seg_mask, det_pred = detect_obstacles(frame, model)

        # ‡∏´‡∏≤‡∏Ñ‡πà‡∏≤ Depth ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ
        object_depths = get_depth_for_detections(depth_map.get_data(), det_pred[0])

        # ‡∏ß‡∏≤‡∏î Bounding Box ‡πÅ‡∏•‡∏∞‡πÅ‡∏™‡∏î‡∏á‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ + ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        if det_pred[0] is not None:
            for i, det in enumerate(det_pred[0]):
                x1, y1, x2, y2, conf, cls = det
                obj_id = i + 1  # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
                label = f'Object {obj_id}'

                # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
                if object_depths[i] is not None:
                    depth_text = f'{object_depths[i]:.2f}m'
                    label += f' ({depth_text})'

                # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö Bounding Box ‡πÅ‡∏•‡∏∞‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
                plot_one_box((x1, y1, x2, y2), frame, label=label, color=(0, 0, 255), line_thickness=2)

                # ‡∏ß‡∏≤‡∏î‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏°‡∏∏‡∏° Bounding Box
                cv2.putText(frame, str(obj_id), (int(x1), int(y1) - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2, cv2.LINE_AA)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        cv2.imshow("Front View - YOLOP", frame)

        # ----------------- ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö -----------------
        print(f"‚úÖ Detection Results - Objects: {len(det_pred[0]) if det_pred[0] is not None else 0}")
        for i, depth in enumerate(object_depths):
            print(f"   ‚ñ∂ Object {i+1}: {depth:.2f} m" if depth is not None else f"   ‚ñ∂ Object {i+1}: No Depth Data")

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏õ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# ----------------- ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á -----------------
zed.close()
cv2.destroyAllWindows()
