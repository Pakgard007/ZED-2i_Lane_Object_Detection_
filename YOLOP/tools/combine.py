import argparse
import os, sys
import time
import torch
import cv2
import numpy as np
import torchvision.transforms as transforms
import pyzed.sl as sl
import torch.nn.functional as F

# Import YOLOP utilities
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from lib.config import cfg
from lib.models import get_net
from lib.core.general import non_max_suppression
from lib.utils import plot_one_box, show_seg_result
from lib.core.general import scale_coords


# Normalize for YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ----------------- ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i -----------------
zed = sl.Camera()
init_params = sl.InitParameters()
init_params.camera_resolution = sl.RESOLUTION.HD720  
init_params.camera_fps = 60
init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE  # ‡πÉ‡∏ä‡πâ Depth Mode
init_params.coordinate_units = sl.UNIT.METER  # ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£  

if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    exit()

image = sl.Mat()
depth_map = sl.Mat()

# ----------------- ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏•‡∏¥‡πÄ‡∏ö‡∏£‡∏ï‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå -----------------
calib_data = np.load("camera_calibration.npz")
mtxL = calib_data["camera_matrix_L"]
distL = np.array([
    -0.07709319689152208,  # k1
     0.06756180189133752,  # k2
     0.00015006759935512075,  # p1 (tangential distortion)
    -6.006342505065124e-05,  # p2 (tangential distortion)
    -0.028545020615709165  # k3
])

extrinsic_data = np.load("extrinsic_parameters.npz")
R = extrinsic_data["R_left"]
T = extrinsic_data["T_left"]

# ----------------- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix -----------------
src_pts = np.array([
    [300, 700], [1000, 700], [550, 300], [750, 300]   
], dtype=np.float32)

dst_pts = np.array([
    [300, 850], [900, 850], [300, 400], [900, 400]   
], dtype=np.float32)

H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)

#-------------------Create ROI----------------------
def create_roi(image, roi_width_pixels=300, roi_height_pixels=700):
    """
    ‡∏™‡∏£‡πâ‡∏≤‡∏á ROI ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏µ‡πà‡∏¢‡∏°‡∏ú‡∏∑‡∏ô‡∏ú‡πâ‡∏≤‡πÅ‡∏ô‡∏ß‡∏ï‡∏±‡πâ‡∏á‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
    roi_width_pixels: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Å‡∏ß‡πâ‡∏≤‡∏á‡∏Ç‡∏≠‡∏á ROI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
    roi_height_pixels: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏≠‡∏á ROI ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÉ‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
    """
    height, width = image.shape[:2]

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á ROI
    x_start = (width - roi_width_pixels) // 2
    y_start = (height - roi_height_pixels) // 2

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á ROI
    roi = image[y_start:y_start + roi_height_pixels, x_start:x_start + roi_width_pixels]

    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö ROI ‡πÉ‡∏ô‡∏†‡∏≤‡∏û Front View (‡πÑ‡∏°‡πà‡πÅ‡∏™‡∏î‡∏á‡πÉ‡∏ô BEV)
    cv2.rectangle(image, (x_start, y_start), (x_start + roi_width_pixels, y_start + roi_height_pixels), (0, 255, 255), 2)

    return roi, (x_start, y_start, roi_width_pixels, roi_height_pixels)

# ----------------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOP -----------------
def load_yolop_model(weights_path, device):
    model = get_net(cfg)
    checkpoint = torch.load(weights_path, map_location=device)
    model.load_state_dict(checkpoint['state_dict'])
    model = model.to(device)
    model.eval()
    print(f"‚úÖ Model Loaded: {weights_path}")
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ Using device: {device}")
model = load_yolop_model("/home/mag/satoi/python/YOLOP/weights/End-to-end.pth", device)

# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Depth ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ -----------------
def get_depth_for_detections(depth_map, detections, roi_coords):
    object_depths = []
    x_roi, y_roi, roi_width, roi_height = roi_coords

    if detections is None or len(detections) == 0:
        return object_depths

    for det in detections:
        x1, y1, x2, y2 = map(int, det[:4])

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Bounding Box ‡∏≠‡∏¢‡∏π‡πà‡∏†‡∏≤‡∏¢‡πÉ‡∏ô ROI ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if x1 < x_roi or x2 > (x_roi + roi_width) or y1 < y_roi or y2 > (y_roi + roi_height):
            object_depths.append(None)
            continue

        obj_depth_roi = depth_map[y1:y2, x1:x2]
        valid_depth = obj_depth_roi[np.isfinite(obj_depth_roi)]
        object_depths.append(np.median(valid_depth) if len(valid_depth) > 0 else None)
    
    return object_depths

def detect_objects_in_roi(roi, roi_coords, model, depth_map):
    da_seg_mask, ll_seg_mask, det_pred = detect_obstacles(roi, model)

    if isinstance(det_pred, torch.Tensor):
        det_pred = det_pred.cpu().numpy()

    object_depths = get_depth_for_detections(depth_map, det_pred[0], roi_coords)
    roi_with_boxes = roi.copy()

    if det_pred[0] is not None:
        for i, det in enumerate(det_pred[0]):
            if len(det) < 6:
                continue
            x1, y1, x2, y2, conf, cls = map(int, det[:6])
            x_roi, y_roi, roi_width, roi_height = roi_coords
            if x1 < x_roi or x2 > (x_roi + roi_width) or y1 < y_roi or y2 > (y_roi + roi_height):
                continue

            label = f"Obj {i+1}"
            if object_depths[i] is not None:
                label += f" ({object_depths[i]:.2f} m)"
            plot_one_box((x1, y1, x2, y2), roi_with_boxes, label=label, color=(0, 0, 255), line_thickness=2)

    return det_pred, roi_with_boxes, object_depths



def decision_making(object_depths):
    if not object_depths:
        return "‚úÖ SAFE: Continue Moving"

    min_depth = min([d for d in object_depths if d is not None], default=None)

    if min_depth is None:
        return "‚úÖ SAFE: Continue Moving"
    elif min_depth < 3.0:
        return "üö´ STOP: Obstacle Ahead!"
    elif min_depth < 5.0:
        return "‚ö† SLOW DOWN: Obstacle Ahead"
    else:
        return "‚úÖ SAFE: Continue Moving"

# ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡πÅ‡∏•‡∏∞ Lane -----------------
def detect_obstacles(image, model):
    input_image = transform(image).to(device)
    input_image = input_image.unsqueeze(0)

    with torch.no_grad():
        det_out, da_seg_out, ll_seg_out = model(input_image)

    _, _, height, width = input_image.shape
    da_seg_out = F.interpolate(da_seg_out, size=(height, width), mode='bilinear', align_corners=False)
    ll_seg_out = F.interpolate(ll_seg_out, size=(height, width), mode='bilinear', align_corners=False)

    da_seg_mask = torch.max(da_seg_out, 1)[1].squeeze().cpu().numpy()
    ll_seg_mask = torch.max(ll_seg_out, 1)[1].squeeze().cpu().numpy()

    # ‡πÉ‡∏ä‡πâ non_max_suppression ‡∏Å‡∏±‡∏ö det_out
    det_pred = non_max_suppression(det_out[0], conf_thres=0.25, iou_thres=0.45)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å non_max_suppression
    return da_seg_mask, ll_seg_mask, det_pred

# ----------------- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏´‡∏¢‡∏∏‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà -----------------
def decision_making(object_detected):
    if object_detected:
        return "üö´ STOP: Obstacle Ahead!"  # ‡∏´‡∏≤‡∏Å‡∏û‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡πÉ‡∏ô ROI
    else:
        return "‚úÖ SAFE: Continue Moving"  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏


def draw_bounding_boxes(image, detections):
    if detections is not None and len(detections):
        for det in detections:
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ det ‡πÄ‡∏õ‡πá‡∏ô numpy array ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
            if isinstance(det, torch.Tensor):
                det = det.cpu().numpy()  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô tensor ‡πÉ‡∏´‡πâ‡∏¢‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏ó‡∏µ‡πà CPU ‡πÅ‡∏•‡∏∞‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array

            det = np.array(det)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array
            det_tensor = torch.tensor(det[:, :4].astype(float), dtype=torch.float32)

            # ‡πÉ‡∏ä‡πâ scale_coords ‡∏Å‡∏±‡∏ö Tensor
            det_tensor = scale_coords(image.shape[:2], det_tensor, image.shape).round()

            # ‡πÅ‡∏õ‡∏•‡∏á‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô numpy.ndarray
            det[:, :4] = det_tensor.numpy().astype(int)

            for *xyxy, conf, cls in reversed(det):
                label = f'Obj {int(cls)} {conf:.2f}'
                plot_one_box(xyxy, image, label=label, color=(0, 0, 255), line_thickness=2)
    return image


# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Overlay Drivable Area & Lane -----------------
def overlay_segmentation(image, mask, color=(0, 255, 0), alpha=0.4):
    overlay = np.zeros_like(image, dtype=np.uint8)
    overlay[mask > 0] = color
    blended = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏Å‡∏ï‡∏¥
    blended = cv2.normalize(blended, None, 0, 255, cv2.NORM_MINMAX)
    
    return blended

# ----------------- ‡πÅ‡∏™‡∏î‡∏á ROI ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô Front View -----------------
def show_roi_in_front_view(image, roi, roi_coords):
    x_start, y_start, roi_width, roi_height = roi_coords
    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ô Front View
    cv2.rectangle(image, (x_start, y_start), (x_start + roi_width, y_start + roi_height), (255, 255, 255), 2)
    return image

def draw_distance_line(image, left_lane_x, real_distance_to_lane):
    """
    ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏µ‡πà‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡πÉ‡∏ô Front View ‡πÇ‡∏î‡∏¢‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
    """
    car_x = image.shape[1] // 2  # ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ (‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û)
    
    # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏™‡πÄ‡∏Å‡∏• (‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ï‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÇ‡∏î‡∏¢‡∏Ñ‡∏£‡πà‡∏≤‡∏ß ‡πÜ)
    scale_factor = 100  # ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏á‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏õ‡∏£‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏™‡∏°‡∏Å‡∏±‡∏ö‡∏†‡∏≤‡∏û)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
    line_start = (car_x, image.shape[0])  # ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏ñ (‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û)
    line_end_x = int(car_x + (real_distance_to_lane * scale_factor))  # ‡πÉ‡∏ä‡πâ scale_factor ‡πÅ‡∏ó‡∏ô pixels_per_meter
    line_end = (line_end_x, 0)  # ‡πÄ‡∏™‡πâ‡∏ô‡∏à‡∏∞‡πÑ‡∏õ‡∏ñ‡∏∂‡∏á‡∏Ç‡∏≠‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô

    # ‡∏™‡∏µ‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏ô‡∏≤
    color = (0, 255, 255)  # ‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á
    thickness = 2

    # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô
    # cv2.line(image, line_start, line_end, color, thickness)
    
    return image

# ----------------- ‡πÅ‡∏õ‡∏•‡∏á Front View ‡πÄ‡∏õ‡πá‡∏ô BEV -----------------
def transform_to_bev(image, H):
    bev = cv2.warpPerspective(image, H, (1280, 720))
    return bev


def get_left_lane_position(ll_seg_mask):
    """ ‡∏´‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏†‡∏≤‡∏û BEV """
    lane_pixels = np.where(ll_seg_mask > 0)  # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏ô
    if len(lane_pixels[0]) == 0:
        return None  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None

    # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    lane_x = lane_pixels[1]  # ‡∏Ñ‡πà‡∏≤ x ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô
    lane_y = lane_pixels[0]  # ‡∏Ñ‡πà‡∏≤ y ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô
    center_x = ll_seg_mask.shape[1] // 2  # ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß x

    # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ center_x ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    left_lane_x = np.min(lane_x)  # ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á x ‡∏Ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
    left_lane_y = lane_y[np.argmin(lane_x)]  # y ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ x ‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
    return (left_lane_x, left_lane_y)


def pixel_to_real_distance(pixel_x, pixel_y, K, R, T):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏•‡∏¥‡πÄ‡∏ö‡∏£‡∏ï‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏Æ‡πÇ‡∏°‡∏à‡∏µ‡πÄ‡∏ô‡∏µ‡∏¢‡∏™ (Homogeneous Coordinates)
    pixel_coords = np.array([[pixel_x], [pixel_y], [1]], dtype=np.float32)

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    camera_coords = np.linalg.inv(K) @ pixel_coords

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á ‚Üí ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏•‡∏Å
    world_coords = np.linalg.inv(R) @ (camera_coords - T)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
    real_distance = np.sqrt(world_coords[0]**2 + world_coords[1]**2)

    return float(real_distance)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å


def track_drivable_area(da_seg_mask, prev_center=None):
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area
    y, x = np.where(da_seg_mask > 0)
    
    if len(x) == 0 or len(y) == 0:  # ‡∏´‡∏≤‡∏Å‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÑ‡∏î‡πâ
        return None, prev_center
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á
    center_x = np.mean(x)
    center_y = np.mean(y)
    
    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡∏ô‡∏µ‡πâ (‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤), ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà
    if prev_center is not None:
        movement_x = center_x - prev_center[0]
        movement_y = center_y - prev_center[1]
        movement = np.sqrt(movement_x**2 + movement_y**2)
        # print(f"‡∏Å‡∏≤‡∏£‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà: {movement:.2f} pixels")
    
    # ‡∏™‡πà‡∏á‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏±‡∏ö (‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡πÉ‡∏ô‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô, ‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡πÉ‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
    return (center_x, center_y), (center_x, center_y)


def draw_distance_line_on_bev(bev_image, left_lane_x, car_x, real_distance_to_lane):
    """
    ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á BEV
    """
    scale_factor = 100  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ï‡∏£‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÇ‡∏î‡∏¢‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì (‡∏Ñ‡πà‡∏≤‡∏õ‡∏£‡∏±‡∏ö‡πÑ‡∏î‡πâ)
    
    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô
    line_start = (car_x, bev_image.shape[0])  # ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏ñ (‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û)
    line_end_x = int(car_x + (real_distance_to_lane * scale_factor))  # ‡πÉ‡∏ä‡πâ scale_factor ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
    line_end = (line_end_x, 0)  # ‡∏à‡∏∏‡∏î‡∏™‡∏¥‡πâ‡∏ô‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô
    
    return bev_image

def draw_distance_line_in_bev(bev_image, left_lane_x, distance_to_lane):
    car_x = bev_image.shape[1] // 2  # ‡∏à‡∏∏‡∏î‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡πÉ‡∏ô BEV
    car_y = bev_image.shape[0] - 50  # ‡πÉ‡∏´‡πâ‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏≤‡∏Å‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏•‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á BEV

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏à‡∏∏‡∏î‡∏õ‡∏•‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏™‡πâ‡∏ô
    line_start = (car_x, car_y)  
    line_end_x = int(left_lane_x)  
    line_end_y = int(car_y - (distance_to_lane * 100))  # ‡∏õ‡∏£‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏Å‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á

    # ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏≠‡∏≠‡∏Å‡∏ô‡∏≠‡∏Å‡∏†‡∏≤‡∏û
    line_end_x = max(0, min(bev_image.shape[1] - 1, line_end_x))
    line_end_y = max(0, min(bev_image.shape[0] - 1, line_end_y))

    return bev_image

def add_text_to_bev(bev_image, distance_to_lane):
    """ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡πÉ‡∏ô BEV """
    if distance_to_lane > 1.0:
        status_text = "‚ùó Far from Lane! Move Left"
        color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
    elif distance_to_lane < 1.0:
        status_text = "‚ùó Too Close to Lane! Move Right"
        color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
    else:
        status_text = "‚úÖ Good Distance"
        color = (0, 255, 0)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô‡∏†‡∏≤‡∏û BEV
    cv2.putText(bev_image, status_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2, cv2.LINE_AA)

    return bev_image

def add_text_to_front_view(front_view_image, distance_to_lane):
    """ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡πÉ‡∏ô Front View """
    if distance_to_lane is None:
        return front_view_image  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏°‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    
    if distance_to_lane > 1.0:
        status_text = "--> Far from Lane! Move Left"
        color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
    elif distance_to_lane < 1.0:
        status_text = "--> Too Close to Lane! Move Right"
        color = (0, 0, 255)  # ‡∏™‡∏µ‡πÅ‡∏î‡∏á
    else:
        status_text = "--> Good Distance"
        color = (0, 255, 0)  # ‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß

    # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡πÉ‡∏ô‡∏†‡∏≤‡∏û Front View
    # cv2.putText(front_view_image, status_text, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

    return front_view_image

def get_center_of_drivable_area_bev(da_seg_bev):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area ‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á BEV
    """
    height, width = da_seg_bev.shape
    y, x = np.where(da_seg_bev > 0)  # ‡∏´‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà

    if len(x) == 0:  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        return width // 2  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏≠

    return int(np.mean(x))  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area ‡πÉ‡∏ô BEV


def is_driving_straight(center_da, center_ref, threshold=20):
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Drivable Area ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û BEV ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô threshold ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î ‚Üí ‡∏Ç‡∏±‡∏ö‡∏ï‡∏£‡∏á‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢
    """
    offset = abs(center_da - center_ref)  # ‡∏´‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πà‡∏≤‡∏á‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á DA ‡∏Å‡∏±‡∏ö ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û BEV

    if offset <= threshold:
        return "‚úÖ Stay Straight"
    else:
        return "‚úÖ Keep Going (Slight Deviation OK)"

def highlight_left_lane(bev_image, left_lane_x, left_lane_y):
    """ ‡∏ß‡∏≤‡∏î‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ß‡∏±‡∏î‡∏£‡∏∞‡∏¢‡∏∞ """
    if left_lane_x is not None and left_lane_y is not None:
        # ‡∏ß‡∏≤‡∏î‡∏ß‡∏á‡∏Å‡∏•‡∏°‡∏™‡∏µ‡∏ô‡πâ‡∏≥‡πÄ‡∏á‡∏¥‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
        cv2.circle(bev_image, (left_lane_x, left_lane_y), 15, (0, 0, 255), -1)
        
        # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÑ‡∏Ç‡∏ß‡πâ X ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏∏‡∏î‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á
        cv2.line(bev_image, (left_lane_x - 10, left_lane_y - 10), (left_lane_x + 10, left_lane_y + 10), (255, 255, 255), 2)
        cv2.line(bev_image, (left_lane_x - 10, left_lane_y + 10), (left_lane_x + 10, left_lane_y - 10), (255, 255, 255), 2)
        
    return bev_image

os.makedirs("output", exist_ok=True)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('/home/mag/satoi/seminar-pre/result.mp4', fourcc, 30.0, (1280, 720))
out1 = cv2.VideoWriter('/home/mag/satoi/seminar-pre/result.mp4', fourcc, 30.0, (1280, 720))

# ----------------- ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö -----------------
prev_center = None
while True:
    if zed.grab() == sl.ERROR_CODE.SUCCESS:
        zed.retrieve_image(image, sl.VIEW.LEFT)
        zed.retrieve_measure(depth_map, sl.MEASURE.DEPTH)
        frame = cv2.cvtColor(image.get_data()[:, :, :3], cv2.COLOR_RGB2BGR)
        frame = cv2.undistort(frame, mtxL, distL)

        # ‡πÅ‡∏Å‡πâ Distortion
        undistorted_frame = cv2.undistort(frame, mtxL, distL)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡πÅ‡∏•‡∏∞ Lane
        da_seg_mask, ll_seg_mask, det_pred = detect_obstacles(undistorted_frame, model)
        frame_with_da = overlay_segmentation(frame.copy(), da_seg_mask, (0, 255, 0))
        frame_with_ll = overlay_segmentation(frame_with_da, ll_seg_mask, (0, 0, 255))
        roi, roi_coords = create_roi(frame_with_ll)
        det_pred, roi_with_boxes, object_depths = detect_objects_in_roi(roi, roi_coords, model, depth_map.get_data())
        decision = decision_making(object_depths)
        cv2.putText(frame_with_ll, decision, (30, 680), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

        print("\n".join([f"‚ñ∂ Object {i+1}: {depth:.2f} m" if depth else f"‚ñ∂ Object {i+1}: No Depth Data" for i, depth in enumerate(object_depths)]))
        print(f"üõë Driving Decision: {decision}")

        cv2.imshow("Front View - YOLOP", frame_with_ll)
        out.write(frame_with_ll)

        # ‡πÅ‡∏ó‡∏£‡∏Ñ‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á Drivable Area
        center, prev_center = track_drivable_area(da_seg_mask, prev_center)

        if center is not None:
            # ‡∏ß‡∏≤‡∏î‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area
            cv2.circle(undistorted_frame, (int(center[0]), int(center[1])), 5, (0, 255, 255), -1)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
        left_lane_pos = get_left_lane_position(ll_seg_mask)
        real_distance_to_lane = None  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV ‡∏Å‡πà‡∏≠‡∏ô
        bev_image = transform_to_bev(undistorted_frame.copy(), H)

        if left_lane_pos:
            left_lane_x, left_lane_y = left_lane_pos
            real_distance_to_lane = float(pixel_to_real_distance(left_lane_x, left_lane_y, mtxL, R, T))
            # üîπ ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏¢‡∏±‡∏á BEV
            left_lane_bev = cv2.perspectiveTransform(np.array([[[left_lane_x, left_lane_y]]], dtype=np.float32), H)
            left_lane_x_bev, left_lane_y_bev = int(left_lane_bev[0][0][0]), int(left_lane_bev[0][0][1])

            # üîπ ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏•‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏à‡∏≠
            cv2.line(bev_image, (left_lane_x_bev, left_lane_y_bev), (left_lane_x_bev, bev_image.shape[0]), (255, 0, 0), 3)

            # üîπ ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÉ‡∏ô **BEV**
            bev_image = draw_distance_line_in_bev(bev_image, left_lane_x, real_distance_to_lane)
            cv2.imshow("Bird's Eye View", bev_image)  # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏†‡∏≤‡∏û
            # üîπ ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÅ‡∏™‡∏î‡∏á‡∏Ñ‡πà‡∏≤‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÉ‡∏ô BEV
            bev_image = add_text_to_bev(bev_image, real_distance_to_lane)

            print(f" ---> ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (Real World): {real_distance_to_lane:.2f} ‡πÄ‡∏°‡∏ï‡∏£")


        # ----------------- ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV -----------------
        bev_image = transform_to_bev(undistorted_frame.copy(), H)

        # ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤ Drivable Area ‡∏≠‡∏¢‡∏π‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà -----------------
        center_da = get_center_of_drivable_area_bev(da_seg_mask)
        driving_status = is_driving_straight(center_da, bev_image.shape[1] // 2)

        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô Terminal -----------------
        print(f"üöó Driving Status: {driving_status}")

        # ----------------- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏á‡∏ö‡∏ô BEV -----------------
        cv2.putText(bev_image, driving_status, (50, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

        # ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ -----------------
        if left_lane_pos:
            left_lane_x, _ = left_lane_pos
            car_x = bev_image.shape[1] // 2  # ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡πÉ‡∏ô BEV

            # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á‡πÉ‡∏ô BEV
            bev_image = draw_distance_line_on_bev(bev_image, left_lane_x, car_x, real_distance_to_lane)
            bev_image = highlight_left_lane(bev_image, left_lane_x, left_lane_y)  # ‡∏ß‡∏≤‡∏î‡∏™‡∏±‡∏ç‡∏•‡∏±‡∏Å‡∏©‡∏ì‡πå‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢

        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• BEV -----------------
        cv2.imshow("Bird's Eye View", bev_image)  # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• BEV ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

        # ----------------- Overlay Drivable Area & Lane ‡∏ö‡∏ô Front View -----------------
        overlay_da = overlay_segmentation(undistorted_frame.copy(), da_seg_mask, (0, 255, 0))  # ‡∏ã‡πâ‡∏≠‡∏ô‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (Drivable Area)
        overlay_ll = overlay_segmentation(overlay_da, ll_seg_mask, (0, 0, 255))  # ‡∏ã‡πâ‡∏≠‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á (Lane)

        # ----------------- ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ overlay_ll (‡πÑ‡∏°‡πà‡∏°‡∏µ ROI) -----------------
        bev_image = transform_to_bev(overlay_ll.copy(), H)  # ‡πÉ‡∏ä‡πâ overlay_ll ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ ROI

        # ----------------- ‡∏™‡∏£‡πâ‡∏≤‡∏á ROI (‡πÄ‡∏â‡∏û‡∏≤‡∏∞ Front View ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô) -----------------
        
        roi, roi_coords = create_roi(overlay_ll)
        det_pred, roi_with_boxes, object_depths = detect_objects_in_roi(roi, roi_coords, model, depth_map.get_data())
        # ‡∏ß‡∏≤‡∏î‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        cv2.imshow("Front View - YOLOP", roi_with_boxes)
        
        object_depths = get_depth_for_detections(depth_map.get_data(), det_pred[0], roi_coords)
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô Terminal
        # if object_depths:
        #     for i, depth in enumerate(object_depths):
        #         if depth is not None:
        #             print(f"‚ñ∂ Object {i+1}: {depth:.2f} m")
        #         else:
        #             print(f"‚ñ∂ Object {i+1}: No Depth Data")

        # # ‡∏ß‡∏≤‡∏î Bounding Box ‡πÅ‡∏•‡∏∞‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ + ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        # if det_pred[0] is not None:
        #     for i, det in enumerate(det_pred[0]):
        #         if len(det) < 6:
        #             continue  

        #         x1, y1, x2, y2, conf, cls = det[:6]

        #         # ‚úÖ ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ROI
        #         x_roi, y_roi, roi_width, roi_height = roi_coords
        #         if x1 < x_roi or x2 > (x_roi + roi_width) or y1 < y_roi or y2 > (y_roi + roi_height):
        #             continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å ROI

        #         obj_id = i + 1
        #         label = f'Object {obj_id}'

        #         if object_depths[i] is not None:
        #             depth_text = f'{object_depths[i]:.2f} m'
        #             label += f' ({depth_text})'
        #         else:
        #             depth_text = "No Depth Data"

        #         plot_one_box((x1, y1, x2, y2), roi_with_boxes, label=label, color=(0, 0, 255), line_thickness=2)
        #         cv2.putText(frame_with_ll, str(obj_id), (int(x1), int(y1) - 10), 
        #                     cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)

        #         print(f"‚ñ∂ Object {obj_id}: {depth_text}")

        # # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à
        # decision = decision_making(object_depths)
        # print(f"üõë Driving Decision: {decision}")
        # cv2.putText(roi_with_boxes, decision, (30, 680), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)


        out.write(roi_with_boxes)

        # ----------------- ‡∏ß‡∏≤‡∏î ROI ‡πÅ‡∏•‡∏∞ Bounding Box ‡∏ö‡∏ô Front View -----------------
        front_view_with_roi = show_roi_in_front_view(overlay_ll, roi, roi_coords)  # ‡πÉ‡∏ä‡πâ overlay_ll ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏°‡∏µ Drivable Area & Lane
        front_view_with_roi = draw_bounding_boxes(front_view_with_roi, det_pred)  # ‡∏ß‡∏≤‡∏î Bounding Box ‡πÉ‡∏ô Front View ‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô


        # ----------------- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô Front View -----------------
        if real_distance_to_lane is not None:
            front_view_with_distance = draw_distance_line(front_view_with_roi, left_lane_x, real_distance_to_lane)  
        else:
            front_view_with_distance = front_view_with_roi  # ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏¥‡∏°‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡πà‡∏≤


        if real_distance_to_lane is not None:
            front_view_with_text = add_text_to_front_view(front_view_with_distance, real_distance_to_lane)
        else:
            front_view_with_text = front_view_with_distance  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ‡πÉ‡∏ä‡πâ‡∏†‡∏≤‡∏û‡πÄ‡∏î‡∏¥‡∏°

        cv2.imshow("Front View - YOLOP", front_view_with_text)

        depth_data = depth_map.get_data()
        print("Max Depth:", np.nanmax(depth_data))
        print("Min Depth:", np.nanmin(depth_data))
        depth_data = (depth_data * 255 / np.max(depth_data)).astype(np.uint8)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô 8-bit
        cv2.imshow("Depth Map", depth_data)

        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Front View -----------------
        cv2.imshow("Front View - YOLOP", front_view_with_distance)  # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÄ‡∏™‡πâ‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        out.write(front_view_with_distance)
        cv2.imshow("Bird's Eye View", bev_image)  # BEV ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà Drivable Area & Lane (‡πÑ‡∏°‡πà‡∏°‡∏µ ROI ‡πÅ‡∏•‡∏∞ Bounding Box)
        out1.write(bev_image)


        # ----------------- ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö -----------------
        object_detected = len(det_pred[0]) > 0 if det_pred else False
        decision = decision_making(object_detected)
        print(f"‚úÖ Detection Results - Drivable Area: {np.sum(da_seg_mask)}, Lanes: {np.sum(ll_seg_mask)}, Objects: {len(det_pred[0]) if det_pred else 0}")
        print(decision)

        # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        if left_lane_pos:
            left_lane_x, _ = left_lane_pos
            real_distance_to_lane = float(pixel_to_real_distance(left_lane_x, left_lane_y, mtxL, R, T))
            print(f" ---> ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (Real World): {float(real_distance_to_lane):.2f} ‡πÄ‡∏°‡∏ï‡∏£")

            # ‡∏õ‡∏£‡∏±‡∏ö‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏£‡∏ñ
            if real_distance_to_lane > 0.8:
                print(" ---> ‡∏≠‡∏¢‡∏π‡πà‡∏´‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí ‡∏Ç‡∏¢‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢")
                steering_command = -1  # ‡∏´‡∏°‡∏∏‡∏ô‡∏û‡∏ß‡∏á‡∏°‡∏≤‡∏•‡∏±‡∏¢‡∏ã‡πâ‡∏≤‡∏¢
            elif real_distance_to_lane < 0.8:
                print(" ---> ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏•‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí ‡∏Ç‡∏¢‡∏±‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢")
                steering_command = 1  # ‡∏´‡∏°‡∏∏‡∏ô‡∏û‡∏ß‡∏á‡∏°‡∏≤‡∏•‡∏±‡∏¢‡∏Ç‡∏ß‡∏≤
            else:
                print(" ---> ‚úÖ ‡∏£‡∏∞‡∏¢‡∏∞‡πÇ‡∏≠‡πÄ‡∏Ñ ‚Üí ‡∏ß‡∏¥‡πà‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ")
                steering_command = 0  # ‡∏ï‡∏£‡∏á‡πÑ‡∏õ

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏õ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

# ----------------- ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á -----------------
out.release()
out1.release()
zed.close()
cv2.destroyAllWindows()

