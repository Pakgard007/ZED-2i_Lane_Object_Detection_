import os, sys
import numpy as np
import cv2
import pyzed.sl as sl
import torch
import torchvision.transforms as transforms
import torch.nn.functional as F
# Import YOLOP utilities
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)
from lib.config import cfg
from lib.models import get_net
from lib.core.general import non_max_suppression
sys.path.append('/home/mag/zed/samples/object detection/birds eye viewer/python')
import ogl_viewer.viewer as gl
import platform

# ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Jetson ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
is_jetson = False
if platform.uname().machine.startswith('aarch64'):
    is_jetson = True

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ‡πÉ‡∏ä‡πâ GPU ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model = get_net(cfg)
weights_path = "/home/mag/satoi/python/YOLOP/weights/End-to-end.pth"
checkpoint = torch.load(weights_path, map_location=device)
model.load_state_dict(checkpoint['state_dict'])
model = model.to(device)
model.eval()

# ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i
zed = sl.Camera()
init_params = sl.InitParameters()
init_params.camera_resolution = sl.RESOLUTION.HD720
init_params.camera_fps = 60
init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE
init_params.coordinate_units = sl.UNIT.METER

if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    exit()

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡∏à‡∏≤‡∏Å YOLOP
def detect_drivable_area(image, model):
    input_image = transform(image).to(device)
    input_image = input_image.unsqueeze(0)

    with torch.no_grad():
        _, da_seg_out, _ = model(input_image)

    da_seg_out = F.interpolate(da_seg_out, size=(image.shape[0], image.shape[1]), mode='bilinear', align_corners=False)
    da_seg_mask = torch.max(da_seg_out, 1)[1].squeeze().cpu().numpy()

    return da_seg_mask

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
def detect_objects(zed, runtime_parameters):
    objects = sl.Objects()
    zed.retrieve_objects(objects, runtime_parameters)
    return objects

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
def calculate_new_path(drivable_area_mask, object_detected):
    if object_detected:
        print("üö´ ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà...")
        return "‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà"
    else:
        return "‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÑ‡∏î‡πâ‡∏ï‡∏≤‡∏°‡∏õ‡∏Å‡∏ï‡∏¥"

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• OpenGL
def display_openGL(zed, viewer, objects, pc_resolution, point_cloud):
    while True:
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ZED
        if zed.grab() == sl.ERROR_CODE.SUCCESS:
            zed.retrieve_measure(point_cloud, sl.MEASURE.XYZRGBA, sl.MEM.CPU, pc_resolution)
            zed.get_position(cam_w_pose, sl.REFERENCE_FRAME.WORLD)

            # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Point Cloud ‡∏î‡πâ‡∏ß‡∏¢ OpenGL
            viewer.updateData(point_cloud, objects)
            cv2.imshow("ZED 3D View", global_image)

            key = cv2.waitKey(1)
            if key == ord('q'):
                break

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô
def main():
    zed = sl.Camera()
    init_params = sl.InitParameters()
    init_params.camera_resolution = sl.RESOLUTION.HD720
    init_params.camera_fps = 60
    init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE
    init_params.coordinate_units = sl.UNIT.METER

    if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
        exit()

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á Viewer ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö OpenGL
    viewer = gl.GLViewer()
    pc_resolution = sl.Resolution(1280, 720)
    viewer.init(zed.get_camera_information().camera_model, pc_resolution, True)
    point_cloud = sl.Mat(pc_resolution.width, pc_resolution.height, sl.MAT_TYPE.F32_C4, sl.MEM.CPU)

    # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏
    runtime_parameters = sl.RuntimeParameters()
    runtime_parameters.confidence_threshold = 50

    while True:
        # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å ZED
        image = sl.Mat()
        zed.grab()
        zed.retrieve_image(image, sl.VIEW.LEFT)
        frame = image.get_data()
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å RGBA ‡πÄ‡∏õ‡πá‡∏ô RGB ‡∏Å‡πà‡∏≠‡∏ô
        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_RGBA2RGB)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area
        da_seg_mask = detect_drivable_area(frame_rgb, model)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏à‡∏≤‡∏Å ZED SDK
        objects = detect_objects(zed, runtime_parameters)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Å‡∏≤‡∏£‡∏û‡∏ö‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏Ç‡∏ß‡∏≤‡∏á‡∏ó‡∏≤‡∏á
        object_detected = False
        for obj in objects.object_list:
            if obj.label == sl.OBJECT_CLASS.PERSON:
                object_detected = True
                break

        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà
        path_status = calculate_new_path(da_seg_mask, object_detected)
        print(f"‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á: {path_status}")

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• OpenGL 3D
        display_openGL(zed, viewer, objects, pc_resolution, point_cloud)

# ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED
zed.close()
cv2.destroyAllWindows()

if __name__ == "__main__":
    main()
