import argparse
import os, sys
import time
import torch
import cv2
import numpy as np
import torchvision.transforms as transforms
import pyzed.sl as sl
import torch.nn.functional as F
import pandas as pd
import math

# Import YOLOP utilities
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from lib.config import cfg
from lib.models import get_net
from lib.core.general import non_max_suppression
from lib.utils import plot_one_box, show_seg_result
from lib.core.general import scale_coords


# Normalize for YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ----------------- ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i -----------------
zed = sl.Camera()
init_params = sl.InitParameters()
init_params.camera_resolution = sl.RESOLUTION.HD720  
init_params.camera_fps = 60
init_params.depth_mode = sl.DEPTH_MODE.PERFORMANCE  # ‡πÉ‡∏ä‡πâ Depth Mode
init_params.coordinate_units = sl.UNIT.METER  # ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£  

if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    exit()

image = sl.Mat()
depth_map = sl.Mat()

# ----------------- ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏•‡∏¥‡πÄ‡∏ö‡∏£‡∏ï‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå -----------------
calib_data = np.load("camera_calibration.npz")
mtxL = calib_data["camera_matrix_L"]
distL = np.array([
    -0.07709319689152208,  # k1
     0.06756180189133752,  # k2
     0.00015006759935512075,  # p1 (tangential distortion)
    -6.006342505065124e-05,  # p2 (tangential distortion)
    -0.028545020615709165  # k3
])

extrinsic_data = np.load("extrinsic_parameters.npz")
R = extrinsic_data["R_left"]
T = extrinsic_data["T_left"]

# ----------------- ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix -----------------
src_pts = np.array([
    [300, 700], [1000, 700], [550, 300], [750, 300]   
], dtype=np.float32)

dst_pts = np.array([
    [300, 850], [900, 850], [300, 400], [900, 400]   
], dtype=np.float32)

H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)

# ----------------- ‡πÇ‡∏´‡∏•‡∏î Waypoint -----------------
df = pd.read_csv("/home/mag/waypoint/GPS_with_PositionXY_updated.csv")
waypoints = df.to_dict(orient="records")
current_wp_index = 0

#-------------------Create ROI----------------------
def create_roi(image, roi_width_pixels=150, roi_height_pixels=500):

    height, width = image.shape[:2]
    x_start = (width - roi_width_pixels) // 2
    y_start = (height - roi_height_pixels) // 2

    # ‡∏ß‡∏≤‡∏î ROI ‡∏•‡∏á‡∏ö‡∏ô‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á
    cv2.rectangle(image, (x_start, y_start), (x_start + roi_width_pixels, y_start + roi_height_pixels), (255, 255, 255), 2)

    roi = image[y_start:y_start + roi_height_pixels, x_start:x_start + roi_width_pixels]
    
    return roi, (x_start, y_start, roi_width_pixels, roi_height_pixels)

# ----------------- ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOP -----------------
def load_yolop_model(weights_path, device):
    model = get_net(cfg)
    checkpoint = torch.load(weights_path, map_location=device)
    model.load_state_dict(checkpoint['state_dict'])
    model = model.to(device)
    model.eval()
    print(f"‚úÖ Model Loaded: {weights_path}")
    return model

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ Using device: {device}")
model = load_yolop_model("/home/mag/satoi/python/YOLOP/weights/End-to-end.pth", device)

# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á Depth ‡∏Ç‡∏≠‡∏á‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÑ‡∏î‡πâ -----------------
def get_depth_for_detections(depth_map, detections, roi_coords):
    object_depths = []
    
    if detections is None or len(detections) == 0:
        return object_depths  

    x_roi, y_roi, roi_width, roi_height = roi_coords

    for det in detections:
        x1, y1, x2, y2 = map(int, det[:4])  

        # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ROI ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if x1 < x_roi or x2 > (x_roi + roi_width) or y1 < y_roi or y2 > (y_roi + roi_height):
            object_depths.append(None)
            continue  

        obj_depth_roi = depth_map[y1:y2, x1:x2]
        valid_depth = obj_depth_roi[np.isfinite(obj_depth_roi)]

        if len(valid_depth) == 0:
            object_depths.append(None)
        else:
            object_depths.append(np.median(valid_depth))
    
    return object_depths

# ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Object, Lane ‡πÅ‡∏•‡∏∞ Drivable Area -----------------
def detect_obstacles(image, model):
    input_image = transform(image).to(device)
    input_image = input_image.unsqueeze(0)

    with torch.no_grad():
        det_out, da_seg_out, ll_seg_out = model(input_image)

    _, _, height, width = input_image.shape
    da_seg_out = F.interpolate(da_seg_out, size=(height, width), mode='bilinear', align_corners=False)
    ll_seg_out = F.interpolate(ll_seg_out, size=(height, width), mode='bilinear', align_corners=False)

    da_seg_mask = torch.max(da_seg_out, 1)[1].squeeze().cpu().numpy()
    ll_seg_mask = torch.max(ll_seg_out, 1)[1].squeeze().cpu().numpy()
    det_pred = non_max_suppression(det_out[0], conf_thres=0.3, iou_thres=0.5)

    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏à‡∏≤‡∏Å non_max_suppression
    return da_seg_mask, ll_seg_mask, det_pred

# ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ üöó
def decision_making(object_depths):
    if not object_depths:
        return "‚úÖ SAFE: Continue Moving"

    min_depth = min([d for d in object_depths if d is not None], default=None)

    if min_depth is None:
        return "‚úÖ SAFE: Continue Moving"
    elif min_depth < 3.0:
        return "üö´ STOP: Obstacle Ahead!"
    elif min_depth < 5.0:
        return "‚ö† SLOW DOWN: Obstacle Ahead"
    else:
        return "‚úÖ SAFE: Continue Moving"

# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô Overlay Drivable Area & Lane -----------------
def overlay_segmentation(image, mask, color=(0, 255, 0), alpha=0.4):
    overlay = np.zeros_like(image, dtype=np.uint8)
    overlay[mask > 0] = color
    blended = cv2.addWeighted(image, 1 - alpha, overlay, alpha, 0)
    
    # ‡∏õ‡∏£‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏ß‡πà‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ä‡πà‡∏ß‡∏á‡∏õ‡∏Å‡∏ï‡∏¥
    blended = cv2.normalize(blended, None, 0, 255, cv2.NORM_MINMAX)
    
    return blended

# ----------------- ‡πÅ‡∏™‡∏î‡∏á ROI ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÉ‡∏ô Front View -----------------
def show_roi_in_front_view(image, roi, roi_coords):
    x_start, y_start, roi_width, roi_height = roi_coords
    # ‡∏ß‡∏≤‡∏î‡∏Å‡∏£‡∏≠‡∏ö‡πÉ‡∏ô Front View
    cv2.rectangle(image, (x_start, y_start), (x_start + roi_width, y_start + roi_height), (255, 255, 255), 2)
    return image

# ----------------- ‡πÅ‡∏õ‡∏•‡∏á Front View ‡πÄ‡∏õ‡πá‡∏ô BEV -----------------
def transform_to_bev(image, H):
    bev = cv2.warpPerspective(image, H, (1280, 720))
    return bev

# ----------------- ‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ -----------------
def get_left_lane_position(ll_seg_mask):
    """ ‡∏´‡∏≤‡πÄ‡∏™‡πâ‡∏ô‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡∏†‡∏≤‡∏û BEV """
    lane_pixels = np.where(ll_seg_mask > 0)  # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏•‡∏ô
    if len(lane_pixels[0]) == 0:
        return None  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÉ‡∏´‡πâ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ None

    # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ‡∏Å‡∏±‡∏ö‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    lane_x = lane_pixels[1]  # ‡∏Ñ‡πà‡∏≤ x ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô
    lane_y = lane_pixels[0]  # ‡∏Ñ‡πà‡∏≤ y ‡∏Ç‡∏≠‡∏á‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô
    center_x = ll_seg_mask.shape[1] // 2  # ‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏†‡∏≤‡∏û‡πÉ‡∏ô‡πÅ‡∏ô‡∏ß x

    # ‡∏´‡∏≤‡∏à‡∏∏‡∏î‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏ó‡∏µ‡πà‡πÉ‡∏Å‡∏•‡πâ center_x ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î
    left_lane_x = np.min(lane_x)  # ‡∏Ñ‡πà‡∏≤‡∏ï‡πà‡∏≥‡∏™‡∏∏‡∏î‡∏Ç‡∏≠‡∏á x ‡∏Ñ‡∏∑‡∏≠‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
    left_lane_y = lane_y[np.argmin(lane_x)]  # y ‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ x ‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
    return (left_lane_x, left_lane_y)


def pixel_to_real_distance(pixel_x, pixel_y, K, R, T):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏•‡∏¥‡πÄ‡∏ö‡∏£‡∏ï‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á
    """
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏Æ‡πÇ‡∏°‡∏à‡∏µ‡πÄ‡∏ô‡∏µ‡∏¢‡∏™ (Homogeneous Coordinates)
    pixel_coords = np.array([[pixel_x], [pixel_y], [1]], dtype=np.float32)

    # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    camera_coords = np.linalg.inv(K) @ pixel_coords

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á ‚Üí ‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏•‡∏Å
    world_coords = np.linalg.inv(R) @ (camera_coords - T)

    # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞‡∏ó‡∏≤‡∏á‡∏à‡∏£‡∏¥‡∏á
    real_distance = np.sqrt(world_coords[0]**2 + world_coords[1]**2)

    return float(real_distance)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô float ‡∏Å‡πà‡∏≠‡∏ô‡∏™‡πà‡∏á‡∏≠‡∏≠‡∏Å

def get_center_of_drivable_area_bev(da_seg_bev):
    """
    ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area ‡πÉ‡∏ô‡∏°‡∏∏‡∏°‡∏°‡∏≠‡∏á BEV
    """
    height, width = da_seg_bev.shape
    y, x = np.where(da_seg_bev > 0)  # ‡∏´‡∏≤‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡∏Ç‡∏µ‡πà

    if len(x) == 0:  # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        return width // 2  # ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤‡∏Å‡∏∂‡πà‡∏á‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏à‡∏≠

    return int(np.mean(x))  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ñ‡πà‡∏≤‡∏Å‡∏•‡∏≤‡∏á‡∏Ç‡∏≠‡∏á Drivable Area ‡πÉ‡∏ô BEV
    
# ----------------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ä‡πà‡∏ß‡∏¢ -----------------
def normalize_angle(angle):
    while angle > math.pi:
        angle -= 2 * math.pi
    while angle < -math.pi:
        angle += 2 * math.pi
    return angle

def find_lookahead_point(car_x, car_y, waypoints, lookahead_distance):
    for wp in waypoints:
        dx = wp["Position_X"] - car_x
        dy = wp["Position_Y"] - car_y
        dist = math.sqrt(dx**2 + dy**2)
        if dist >= lookahead_distance:
            return wp
    return waypoints[-1] # ‡∏Å‡∏£‡∏ì‡∏µ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏´‡πà‡∏≤‡∏á‡∏û‡∏≠

def pure_pursuit_control(car_x, car_y, car_theta, wp, L=1.2, L_d=2.0):
    dx = wp["Position_X"] - car_x
    dy = wp["Position_Y"] - car_y
    target_theta = math.atan2(dy, dx)
    alpha = normalize_angle(target_theta - car_theta)
    delta = math.atan2(2 * L * math.sin(alpha), L_d)

    distance = math.sqrt(dx ** 2 + dy ** 2)
    if distance > 2.0:
        speed = 0.5
    elif distance > 0.5:
        speed = 0.3
    else:
        speed = 0.0

    return delta, speed, distance

# ----------------- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏£‡∏∞‡∏ö‡∏ö -----------------
mode = "yolop"
car_x = waypoints[0]["Position_X"]
car_y = waypoints[0]["Position_Y"]
car_theta = waypoints[0]["orientation"]

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏ß‡πà‡∏≤ YOLOP ‡πÄ‡∏û‡∏µ‡πâ‡∏¢‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
# ‡πÄ‡∏ä‡πà‡∏ô ‡∏Å‡∏£‡∏ì‡∏µ lane detection ‡∏´‡∏≤‡∏¢ ‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏±‡∏ö‡πÄ‡∏ö‡∏µ‡πà‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏°‡∏≤‡∏Å

def is_yolop_reliable(center_da, image_width, lane_found, deviation_threshold=80):
    center_offset = abs(center_da - image_width // 2)
    return lane_found and center_offset <= deviation_threshold

def world_to_pixel(x, y, origin_x=0, origin_y=0, scale=20):
    """
    ‡πÅ‡∏õ‡∏•‡∏á‡∏Ñ‡πà‡∏≤‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á (‡πÄ‡∏°‡∏ï‡∏£) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•‡πÉ‡∏ô‡∏†‡∏≤‡∏û BEV
    - origin_x, origin_y: ‡∏à‡∏∏‡∏î‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á (‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡πÇ‡∏•‡∏Å‡∏ó‡∏µ‡πà‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î (0,0) ‡πÉ‡∏ô‡∏†‡∏≤‡∏û)
    - scale: ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏Ç‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏°‡∏ï‡∏£ ‚Üí ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏• (‡∏Ñ‡πà‡∏≤‡∏ó‡∏±‡πà‡∏ß‡πÑ‡∏õ 20-100)
    """
    px = int((x - origin_x) * scale)
    py = int((y - origin_y) * scale)
    return px, py

def draw_heading_on_bev(image, car_x, car_y, car_theta, origin_x=0, origin_y=0, scale=20, length=3.0):
    h, w = image.shape[:2]

    # ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏£‡∏¥‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
    start_px, start_py = world_to_pixel(car_x, car_y, origin_x, origin_y, scale)
    end_x = car_x + length * math.cos(car_theta)
    end_y = car_y + length * math.sin(car_theta)
    end_px, end_py = world_to_pixel(end_x, end_y, origin_x, origin_y, scale)

    print(f"üü¢ Heading: Start({start_px}, {start_py}) ‚Üí End({end_px}, {end_py}) | angle={math.degrees(car_theta):.1f}¬∞")

    # ‡πÄ‡∏ä‡πá‡∏Å‡∏ß‡πà‡∏≤‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏†‡∏≤‡∏û
    if 0 <= start_px < w and 0 <= start_py < h and 0 <= end_px < w and 0 <= end_py < h:
        cv2.arrowedLine(image, (start_px, start_py), (end_px, end_py), (0, 0, 255), 4, tipLength=0.2)
    else:
        print("‚ùå ‡πÄ‡∏™‡πâ‡∏ô‡∏´‡∏•‡∏∏‡∏î‡∏ô‡∏≠‡∏Å BEV (‡∏´‡∏•‡∏±‡∏á‡πÅ‡∏õ‡∏•‡∏á‡πÅ‡∏•‡πâ‡∏ß)")
    
def draw_drivable_rows(bev_image, da_seg_bev_mask, num_lines=9, slope_threshold=0.05):
    """
    - ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÅ‡∏ô‡∏ß‡∏ô‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏ö‡∏£‡∏¥‡πÄ‡∏ß‡∏ì Drivable Area
    - ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á‡∏à‡∏≤‡∏Å‡∏à‡∏∏‡∏î‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á
    - ‡∏Ñ‡∏∑‡∏ô‡∏Ñ‡πà‡∏≤ True/False ‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Ç‡∏±‡∏ö‡∏ï‡∏£‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """
    height, width = da_seg_bev_mask.shape
    y_indices = np.linspace(-100, height - 1, num_lines).astype(int)
    centers = []

    for y in y_indices:
        row = da_seg_bev_mask[y]
        x_indices = np.where(row > 0)[0]  # ‡∏û‡∏¥‡∏Å‡∏±‡∏î x ‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Drivable Area

        if len(x_indices) > 0:
            x_min, x_max = np.min(x_indices), np.max(x_indices)
            x_center = (x_min + x_max) // 2
            centers.append((x_center, y))
            cv2.line(bev_image, (x_min, y), (x_max, y), (0, 0, 255), 2)
            cv2.circle(bev_image, (x_center, y), 5, (0, 255, 255), -1)

    # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏à‡∏∏‡∏î‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 2 ‡∏à‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì‡πÄ‡∏™‡πâ‡∏ô‡∏ï‡∏£‡∏á
    if len(centers) >= 4:
        pts = np.array(centers)
        coeffs = np.polyfit(pts[:, 1], pts[:, 0], 1)  # fit x = m*y + c
        slope = coeffs[0]

        # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì
        y0, y1 = 0, height - 1
        x0 = int(coeffs[0] * y0 + coeffs[1])
        x1 = int(coeffs[0] * y1 + coeffs[1])
        cv2.line(bev_image, (x0, y0), (x1, y1), (0, 255, 0), 2)

        # ‡∏ï‡∏±‡∏î‡∏™‡∏¥‡∏ô‡πÉ‡∏à‡∏ß‡πà‡∏≤‡∏Ñ‡∏ß‡∏£‡∏Ç‡∏±‡∏ö‡∏ï‡∏£‡∏á‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        if abs(slope) < slope_threshold:
            cv2.putText(bev_image, "Move Straight", (50, height - 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
            return True
        else:
            cv2.putText(bev_image, "Not Straight Enough", (50, height - 60),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
            return False
    else:
        cv2.putText(bev_image, "Not Enough Points", (50, height - 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)
        return False

os.makedirs("output", exist_ok=True)
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('/home/mag/satoi/seminar-pre/result-Front-latest4.mp4', fourcc, 30.0, (1280, 720))
out1 = cv2.VideoWriter('/home/mag/satoi/seminar-pre/result-BEV-latest4.mp4', fourcc, 30.0, (1280, 720))

# ----------------- ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i ‡πÅ‡∏•‡∏∞‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö -----------------
prev_center = None
trajectory_points = []

image = sl.Mat()
depth_map = sl.Mat()

while True:
    if zed.grab() == sl.ERROR_CODE.SUCCESS:
        zed.retrieve_image(image, sl.VIEW.LEFT)
        zed.retrieve_measure(depth_map, sl.MEASURE.DEPTH)
        frame = image.get_data()[:, :, :3]  
        frame = cv2.cvtColor(frame, cv2.COLOR_RGBA2BGR)  

        # ‡πÅ‡∏Å‡πâ Distortion
        undistorted_frame = cv2.undistort(frame, mtxL, distL)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö Drivable Area ‡πÅ‡∏•‡∏∞ Lane
        da_seg_mask, ll_seg_mask, det_pred = detect_obstacles(undistorted_frame, model)

        # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏™‡∏∏‡∏î
        left_lane_pos = get_left_lane_position(ll_seg_mask)
        real_distance_to_lane = None  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏Ñ‡πà‡∏≤‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV ‡∏Å‡πà‡∏≠‡∏ô
        bev_image = transform_to_bev(undistorted_frame.copy(), H)

        left_lane_history = []
        max_history = 5

        if left_lane_pos:
            left_lane_x, left_lane_y = left_lane_pos
            left_lane_bev = cv2.perspectiveTransform(np.array([[[left_lane_x, left_lane_y]]], dtype=np.float32), H)
            left_lane_x_bev = int(left_lane_bev[0][0][0])  # X ‡πÉ‡∏ô BEV
            left_lane_y_bev = int(left_lane_bev[0][0][1])  # Y ‡πÉ‡∏ô BEV

            real_distance_to_lane = float(pixel_to_real_distance(left_lane_x, left_lane_y, mtxL, R, T))
            
            # üîπ ‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡πÑ‡∏õ‡∏¢‡∏±‡∏á BEV
            left_lane_bev = cv2.perspectiveTransform(np.array([[[left_lane_x, left_lane_y]]], dtype=np.float32), H)
            left_lane_x_bev, left_lane_y_bev = int(left_lane_bev[0][0][0]), int(left_lane_bev[0][0][1])

            cv2.imshow("Bird's Eye View", bev_image)  # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏†‡∏≤‡∏û
            print(f" ---> ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (Real World): {real_distance_to_lane:.2f} ‡πÄ‡∏°‡∏ï‡∏£")

        # ----------------- ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV -----------------
        bev_image = transform_to_bev(undistorted_frame.copy(), H)

        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á car_x, car_y ‚Üí ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏• (‡∏≠‡∏¥‡∏á‡∏ï‡∏≤‡∏°‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û 1280x720 ‡∏´‡∏£‡∏∑‡∏≠ scaling ‡πÄ‡∏≠‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ)
        px = int(car_x * 100)  # scale ‡∏à‡∏≤‡∏Å‡πÄ‡∏°‡∏ï‡∏£ ‚Üí ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
        py = int(car_y * 100)

        trajectory_points.append((px, py))

        # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡∏ó‡∏≤‡∏á‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á (‡∏à‡∏∏‡∏î‡∏™‡∏µ‡πÅ‡∏î‡∏á)
        for pt in trajectory_points:
            cv2.circle(bev_image, pt, 2, (0, 0, 255), -1)

        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• BEV -----------------
        cv2.imshow("Bird's Eye View", bev_image)  # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• BEV ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÅ‡∏•‡∏∞‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°

        # ----------------- Overlay Drivable Area & Lane ‡∏ö‡∏ô Front View -----------------
        overlay_da = overlay_segmentation(undistorted_frame.copy(), da_seg_mask, (0, 255, 0))  # ‡∏ã‡πâ‡∏≠‡∏ô‡∏™‡∏µ‡πÄ‡∏Ç‡∏µ‡∏¢‡∏ß (Drivable Area)
        overlay_ll = overlay_segmentation(overlay_da, ll_seg_mask, (0, 0, 255))  # ‡∏ã‡πâ‡∏≠‡∏ô‡∏™‡∏µ‡πÅ‡∏î‡∏á (Lane)

        # ----------------- ‡∏™‡∏£‡πâ‡∏≤‡∏á BEV ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ overlay_ll (‡πÑ‡∏°‡πà‡∏°‡∏µ ROI) -----------------
        bev_image = transform_to_bev(overlay_ll.copy(), H)  # ‡πÉ‡∏ä‡πâ overlay_ll ‡∏ó‡∏µ‡πà‡πÑ‡∏°‡πà‡∏°‡∏µ ROI
        scale = bev_image.shape[1] / 12.8   # 100 pixels = 1 meter ‚Üí 12.8 m = 1280 px
        # draw_heading_on_bev(bev_image, car_x, car_y, car_theta, origin_x=car_x - 6.4, origin_y=car_y - 3.6, scale=100)
        # üü° ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏®‡∏π‡∏ô‡∏¢‡πå‡∏Å‡∏•‡∏≤‡∏á‡∏ö‡∏ô‡πÅ‡∏ô‡∏ß‡∏Ç‡∏ß‡∏≤‡∏á‡∏´‡∏•‡∏≤‡∏¢‡∏à‡∏∏‡∏î
        da_seg_mask_uint8 = (da_seg_mask > 0).astype(np.uint8) * 255
        da_seg_bev_mask = cv2.warpPerspective(da_seg_mask_uint8, H, (1280, 720))
        should_go_straight = draw_drivable_rows(bev_image, da_seg_bev_mask, num_lines=9)

        if should_go_straight:
            speed = 0.4
            steering_command = 0
        else:
            speed = 0.0
            steering_command = 0
            print("‚ùó ‡πÄ‡∏™‡πâ‡∏ô‡πÑ‡∏°‡πà‡∏ï‡∏£‡∏á‡∏û‡∏≠ ‚Üí ‡πÑ‡∏°‡πà‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏ó‡∏µ‡πà")

        # ----------------- ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏ô Front View -----------------
        # ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ default ‡πÄ‡∏õ‡πá‡∏ô overlay_ll
        front_view_with_distance = overlay_ll.copy()
        
        # ‡πÉ‡∏ä‡πâ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì
        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏™‡πâ‡∏ô heading ‡πÅ‡∏•‡∏∞‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢‡∏ö‡∏ô BEV -----------------
        if left_lane_pos:
            left_lane_x, left_lane_y = left_lane_pos
            real_distance_to_lane = float(pixel_to_real_distance(left_lane_x, left_lane_y, mtxL, R, T))
            print(f" ---> ‡∏£‡∏∞‡∏¢‡∏∞‡∏à‡∏≤‡∏Å‡∏Ç‡∏≠‡∏ö‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (Real World): {real_distance_to_lane:.2f} ‡πÄ‡∏°‡∏ï‡∏£")
            print("üìç left_lane_pos =", left_lane_pos)

            # ‡∏à‡∏∏‡∏î‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ‡πÉ‡∏ô‡∏û‡∏¥‡∏Å‡∏±‡∏î‡πÇ‡∏•‡∏Å
            start_world = np.array([car_x, car_y])
            heading_length = 2.0  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏™‡πâ‡∏ô heading (‡∏´‡∏ô‡πà‡∏ß‡∏¢‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏°‡∏ï‡∏£)
            end_world = start_world + heading_length * np.array([np.cos(car_theta), np.sin(car_theta)])

            # ‡πÅ‡∏õ‡∏•‡∏á world ‚Üí pixel
            origin_x = car_x - 6.4  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î origin X ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ
            origin_y = car_y - 3.6  # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î origin Y ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ
            scale = 100  # 1 ‡πÄ‡∏°‡∏ï‡∏£ = 100 ‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•

            def world_to_pixel(x, y, origin_x, origin_y, scale=100):
                px = int((x - origin_x) * scale)
                py = int((y - origin_y) * scale)
                return px, py

            start_px, start_py = world_to_pixel(start_world[0], start_world[1], origin_x, origin_y, scale)
            slope = np.tan(car_theta)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì slope ‡∏à‡∏≤‡∏Å car_theta

            height = bev_image.shape[0]  # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏π‡∏á‡∏Ç‡∏≠‡∏á‡∏†‡∏≤‡∏û BEV

            # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô heading ‡πÄ‡∏ï‡πá‡∏°‡∏à‡∏≠ (‡∏™‡∏µ‡πÄ‡∏´‡∏•‡∏∑‡∏≠‡∏á)
            # try:
            #     x0 = int(start_px - (start_py) / slope)      # y = 0
            #     x1 = int(start_px + (height - start_py) / slope)  # y = height
            #     cv2.line(bev_image, (x0, 0), (x1, height), (0, 255, 255), 2)
            # except ZeroDivisionError:
            #     # ‡∏Å‡∏£‡∏ì‡∏µ‡∏°‡∏∏‡∏° 90¬∞ (‡∏ï‡∏£‡∏á‡∏û‡∏≠‡∏î‡∏µ)
            #     cv2.line(bev_image, (start_px, 0), (start_px, height), (0, 255, 255), 2)

            # ‡∏ß‡∏≤‡∏î‡πÄ‡∏™‡πâ‡∏ô‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢ (‡∏™‡∏µ‡∏ü‡πâ‡∏≤) ‡πÅ‡∏ô‡∏ß‡∏î‡∏¥‡πà‡∏á ‡πÇ‡∏î‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡∏û‡∏¥‡∏Å‡∏±‡∏î‡∏à‡∏≤‡∏Å world ‚Üí pixel
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢
            left_lane_history.append(left_lane_x)
            if len(left_lane_history) > max_history:
                left_lane_history.pop(0)

            # ‡πÉ‡∏ä‡πâ‡∏Ñ‡πà‡∏≤‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢‡∏Ç‡∏≠‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡πÅ‡∏ó‡∏ô‡∏Ñ‡πà‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô
            smooth_left_lane_x = int(np.mean(left_lane_history))
            lane_px, _ = world_to_pixel(smooth_left_lane_x, car_y, origin_x, origin_y, scale)
            cv2.line(bev_image, (lane_px, 0), (lane_px, bev_image.shape[0]), (255, 0, 0), 2)

            # (Optional) ‡πÉ‡∏™‡πà‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡πà‡∏ß‡∏¢ debug
            distance_text = f"Lane Distance : {real_distance_to_lane:.2f} m"
            cv2.putText(bev_image, distance_text, (50, 150), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            cv2.putText(bev_image, f"MODE : {mode.upper()}", (50, 100), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)
            cv2.imshow("Bird's Eye View", bev_image)  # BEV ‡∏°‡∏µ‡πÅ‡∏Ñ‡πà Drivable Area & Lane (‡πÑ‡∏°‡πà‡∏°‡∏µ ROI ‡πÅ‡∏•‡∏∞ Bounding Box)
            
            # ‡∏õ‡∏£‡∏±‡∏ö‡∏ó‡∏¥‡∏®‡∏ó‡∏≤‡∏á‡∏£‡∏ñ
            if real_distance_to_lane > 0.8:
                print(" ---> ‡∏≠‡∏¢‡∏π‡πà‡∏´‡πà‡∏≤‡∏á‡πÄ‡∏•‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí ‡∏Ç‡∏¢‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢")
                steering_command = -1  # ‡∏´‡∏°‡∏∏‡∏ô‡∏û‡∏ß‡∏á‡∏°‡∏≤‡∏•‡∏±‡∏¢‡∏ã‡πâ‡∏≤‡∏¢
            elif real_distance_to_lane < 0.8:
                print(" ---> ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏Å‡∏•‡πâ‡πÄ‡∏•‡∏ô‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‚Üí ‡∏Ç‡∏¢‡∏±‡∏ö‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÄ‡∏•‡∏ô‡∏ã‡πâ‡∏≤‡∏¢")
                steering_command = 1  # ‡∏´‡∏°‡∏∏‡∏ô‡∏û‡∏ß‡∏á‡∏°‡∏≤‡∏•‡∏±‡∏¢‡∏Ç‡∏ß‡∏≤
            else:
                print(" ---> ‚úÖ ‡∏£‡∏∞‡∏¢‡∏∞‡πÇ‡∏≠‡πÄ‡∏Ñ ‚Üí ‡∏ß‡∏¥‡πà‡∏á‡∏ï‡∏£‡∏á‡πÑ‡∏õ")
                steering_command = 0  # ‡∏ï‡∏£‡∏á‡πÑ‡∏õ

        # ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡∏•‡∏π‡∏õ
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

        frame_with_da = overlay_segmentation(frame.copy(), da_seg_mask, (0, 255, 0))  
        frame_with_ll = overlay_segmentation(frame_with_da, ll_seg_mask, (0, 0, 255))  
        roi, roi_coords = create_roi(frame_with_ll)
        object_depths = get_depth_for_detections(depth_map.get_data(), det_pred[0], roi_coords)

        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÉ‡∏ô Terminal
        if object_depths:
            for i, depth in enumerate(object_depths):
                if depth is not None:
                    print(f"‚ñ∂ Object {i+1}: {depth:.2f} m")
                else:
                    print(f"‚ñ∂ Object {i+1}: No Depth Data")

        # ‡∏ß‡∏≤‡∏î Bounding Box ‡πÅ‡∏•‡∏∞‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏•‡∏Ç‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏ + ‡∏£‡∏∞‡∏¢‡∏∞‡∏´‡πà‡∏≤‡∏á
        if det_pred[0] is not None:
            for i, det in enumerate(det_pred[0]):
                if len(det) < 6:
                    continue  

                x1, y1, x2, y2, conf, cls = det[:6]

                # ‚úÖ ‡πÄ‡∏á‡∏∑‡πà‡∏≠‡∏ô‡πÑ‡∏Ç‡∏Å‡∏£‡∏≠‡∏ö‡∏ï‡πâ‡∏≠‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô ROI
                x_roi, y_roi, roi_width, roi_height = roi_coords
                if x1 < x_roi or x2 > (x_roi + roi_width) or y1 < y_roi or y2 > (y_roi + roi_height):
                    continue  # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ß‡∏±‡∏ï‡∏ñ‡∏∏‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏π‡πà‡∏ô‡∏≠‡∏Å ROI

                obj_id = i + 1
                label = f'Object {obj_id}'

                if object_depths[i] is not None:
                    depth_text = f'{object_depths[i]:.2f} m'
                    label += f' ({depth_text})'
                else:
                    depth_text = "No Depth Data"

                plot_one_box((x1, y1, x2, y2), frame_with_ll, label=label, color=(0, 0, 255), line_thickness=2)
                cv2.putText(frame_with_ll, str(obj_id), (int(x1), int(y1) - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 255), 2, cv2.LINE_AA)

                print(f"‚ñ∂ Object {obj_id}: {depth_text}")


        decision = decision_making(object_depths)
        print(f"üõë Driving Decision: {decision}")
        cv2.imshow("Front View - YOLOP", frame_with_ll)

        # ----------------- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• Front View -----------------
        out.write(frame_with_ll)
        out1.write(bev_image)

        lane_found = left_lane_pos is not None
        center_da = get_center_of_drivable_area_bev(da_seg_mask)

        # ----------------- ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡πÇ‡∏´‡∏°‡∏î‡πÄ‡∏õ‡πá‡∏ô YOLOP ‡∏´‡∏£‡∏∑‡∏≠ Pure Pursuit -----------------
        if is_yolop_reliable(center_da, bev_image.shape[1], lane_found):
            mode = "yolop"
            if real_distance_to_lane > 0.8:
                steering_command = -1
            elif real_distance_to_lane < 0.8:
                steering_command = 1
            else:
                steering_command = 0
            speed = 0.4
        else:
            mode = "pure_pursuit"
            wp = find_lookahead_point(car_x, car_y, waypoints, lookahead_distance=2.0)
            steering_angle, speed, dist = pure_pursuit_control(car_x, car_y, car_theta, wp)
            
            # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡πÉ‡∏ô‡πÄ‡∏ó‡∏≠‡∏£‡πå‡∏°‡∏¥‡∏ô‡∏≠‡∏•
            print(f"üõ£Ô∏è Pure Pursuit Mode")
            print(f"  Waypoint Index: {current_wp_index}")
            print(f"  Waypoint: x={wp['Position_X']}, y={wp['Position_Y']}")
            print(f"  Steering Angle Œ¥ (radians): {steering_angle:.3f} rad")
            print(f"  Distance to Waypoint: {dist:.2f} meters")
            print(f"  Speed: {speed:.2f} m/s")
            
            # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏ñ (‡πÉ‡∏ä‡πâ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ SLAM/GPS ‡∏à‡∏£‡∏¥‡∏á)
            dt = 0.1  # timestep
            car_theta += steering_angle * dt  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏°‡∏∏‡∏°‡∏Ç‡∏≠‡∏á‡∏£‡∏ñ
            car_theta = normalize_angle(car_theta)  # ‡∏õ‡∏£‡∏±‡∏ö‡∏°‡∏∏‡∏°‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á -pi ‡∏ñ‡∏∂‡∏á +pi
            car_x += speed * math.cos(car_theta) * dt  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á x
            car_y += speed * math.sin(car_theta) * dt  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á y

            if dist < 0.5 and current_wp_index < len(waypoints) - 1:
                current_wp_index += 1  # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï waypoint index

        # ‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ï‡∏≥‡πÅ‡∏´‡∏ô‡πà‡∏á‡∏£‡∏ñ
        print(f"üß† Mode: {mode} | Speed: {speed:.2f} | Steering: {steering_angle if mode=='pure_pursuit' else steering_command} | WP Index: {current_wp_index}")

# ----------------- ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á -----------------
out.release()
out1.release()
zed.close()
cv2.destroyAllWindows()

