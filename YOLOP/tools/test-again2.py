import pyzed.sl as sl
import cv2
import numpy as np
import torch
import torchvision.transforms as transforms
import os, sys

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

# YOLOP Modules
from lib.config import cfg
from lib.models import get_net
from lib.utils import show_seg_result
from lib.core.general import non_max_suppression

# ----------------- 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOP -----------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ Using device: {device}")
model = get_net(cfg).to(device)
model.load_state_dict(torch.load("YOLOP/weights/End-to-end.pth", map_location=device)['state_dict'])
model.eval()

# Normalization ‡∏ï‡∏≤‡∏° YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ----------------- 2Ô∏è‚É£ ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ZED 2i -----------------
zed = sl.Camera()
init_params = sl.InitParameters(camera_resolution=sl.RESOLUTION.HD720, camera_fps=30, depth_mode=sl.DEPTH_MODE.NONE)
if zed.open(init_params) != sl.ERROR_CODE.SUCCESS:
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏î‡πâ!")
    exit()
image = sl.Mat()

# ----------------- 3Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏≤‡∏•‡∏¥‡πÄ‡∏ö‡∏£‡∏ï & Homography Matrix -----------------
calib_data = np.load("camera_calibration.npz")
mtxL = calib_data["camera_matrix_L"]
distL = np.array([
    -0.07709319689152208,  # k1
     0.06756180189133752,  # k2
     0.00015006759935512075,  # p1 (tangential distortion)
    -6.006342505065124e-05,  # p2 (tangential distortion)
    -0.028545020615709165  # k3
])

# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏à‡∏∏‡∏î‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Homography Matrix (‡∏ñ‡πâ‡∏≤‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î)
src_pts = np.array([[300, 600], [1000, 600], [500, 300], [800, 300]], dtype=np.float32)
dst_pts = np.array([[300, 850], [900, 850], [300, 400], [900, 400]], dtype=np.float32)
H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)

# ----------------- 4Ô∏è‚É£ ‡∏ß‡∏ô‡∏•‡∏π‡∏õ ‡∏≠‡πà‡∏≤‡∏ô‡∏†‡∏≤‡∏û ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ YOLOP + BEV -----------------
while True:
    try:
        if zed.grab() == sl.ERROR_CODE.SUCCESS:
            zed.retrieve_image(image, sl.VIEW.LEFT)
            frame = image.get_data()[:, :, :3]
            frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)

            # üîπ ‡πÅ‡∏Å‡πâ Distortion
            undistorted_frame = cv2.undistort(frame, mtxL, distL)

            # üîπ Resize ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö YOLOP
            frame_resized = cv2.resize(undistorted_frame, (640, 640))
            input_tensor = transform(frame_resized).unsqueeze(0).to(device)

            # üîπ ‡∏ó‡∏≥ Object Detection & Lane Detection ‡∏î‡πâ‡∏ß‡∏¢ YOLOP
            with torch.no_grad():
                det_out, da_seg_out, ll_seg_out = model(input_tensor)

            # üîπ ‡πÉ‡∏ä‡πâ argmax ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡∏°‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏û‡∏¥‡∏Å‡πÄ‡∏ã‡∏•
            da_seg_out = np.argmax(da_seg_out.sigmoid().cpu().numpy(), axis=1).squeeze(0)
            ll_seg_out = np.argmax(ll_seg_out.sigmoid().cpu().numpy(), axis=1).squeeze(0)

            # üîπ ‡πÉ‡∏ä‡πâ show_seg_result() ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏°‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            img_det = show_seg_result(frame_resized, (da_seg_out, ll_seg_out), index=0, epoch=0, is_demo=True)

            # üîπ ‡πÅ‡∏õ‡∏•‡∏á‡∏†‡∏≤‡∏û‡πÄ‡∏õ‡πá‡∏ô Bird‚Äôs Eye View (BEV)
            bev_image = cv2.warpPerspective(img_det, H, (1280, 720))

            # üîπ ‡∏õ‡∏£‡∏±‡∏ö‡∏Ç‡∏ô‡∏≤‡∏î‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            front_resized = cv2.resize(img_det, (640, 720))
            bev_resized = cv2.resize(bev_image, (640, 720))

            # üîπ ‡∏£‡∏ß‡∏°‡∏†‡∏≤‡∏û‡πÅ‡∏ö‡∏ö Side-by-Side
            frame_output = cv2.hconcat([front_resized, bev_resized])

            # üîπ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
            cv2.imshow("YOLOP + BEV (ZED 2i)", frame_output)

            # üîπ ‡∏Å‡∏î 'q' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        break

# ----------------- 5Ô∏è‚É£ ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏¥‡∏î‡∏´‡∏ô‡πâ‡∏≤‡∏ï‡πà‡∏≤‡∏á -----------------
zed.close()
cv2.destroyAllWindows()
