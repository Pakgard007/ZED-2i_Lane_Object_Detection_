import cv2
import torch
import numpy as np
import torchvision.transforms as transforms
import os, sys

# ---------------- 1Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• YOLOP ----------------
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(BASE_DIR)

from lib.config import cfg
from lib.models import get_net
from lib.utils import show_seg_result

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"üîπ Using device: {device}")

model = get_net(cfg).to(device)
model.load_state_dict(torch.load("YOLOP/weights/End-to-end.pth", map_location=device)['state_dict'])
model.eval()

# ‚úÖ Normalization ‡∏ï‡∏≤‡∏° YOLOP
normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
transform = transforms.Compose([transforms.ToTensor(), normalize])

# ---------------- 2Ô∏è‚É£ ‡πÇ‡∏´‡∏•‡∏î‡∏Ñ‡πà‡∏≤‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏Ç‡∏≠‡∏á‡∏Å‡∏•‡πâ‡∏≠‡∏á ----------------
calib_data = np.load("camera_calibration.npz")
mtxL = calib_data["camera_matrix_L"]
distL = np.array([-0.077, 0.067, 0.00015, -0.00006, -0.028])

extrinsic_data = np.load("extrinsic_parameters.npz")
R = extrinsic_data["R_left"]
T = extrinsic_data["T_left"]

# ‚úÖ ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Homography Matrix ‡πÇ‡∏î‡∏¢‡πÉ‡∏ä‡πâ‡∏Å‡∏≤‡∏£‡πÅ‡∏°‡∏ô‡∏ô‡∏ß‡∏•‡∏à‡∏∏‡∏î
src_pts = np.array([[300, 700], [1000, 700], [550, 300], [750, 300]], dtype=np.float32)
dst_pts = np.array([[300, 850], [900, 850], [300, 400], [900, 400]], dtype=np.float32)
H, _ = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC)

# ---------------- 3Ô∏è‚É£ ‡πÄ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ----------------
video_path = "/home/mag/satoi/final.mp4"  # üîπ ‡πÄ‡∏õ‡∏•‡∏µ‡πà‡∏¢‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏û‡∏≤‡∏ò‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì
cap = cv2.VideoCapture(video_path)

if not cap.isOpened():
    print("‚ùå ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡πÑ‡∏î‡πâ!")
    exit()

# ---------------- 4Ô∏è‚É£ ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏£‡πâ‡∏≤‡∏á Occupancy Grid Map -----------------
def create_occupancy_grid(drivable_area):
    height, width = drivable_area.shape
    grid = np.zeros((height, width), dtype=np.uint8)
    grid[drivable_area > 0] = 0  # ‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÑ‡∏î‡πâ = 0 (‡∏î‡∏≥)
    grid[drivable_area == 0] = 1  # ‡∏™‡∏¥‡πà‡∏á‡∏Å‡∏µ‡∏î‡∏Ç‡∏ß‡∏≤‡∏á = 1 (‡∏Ç‡∏≤‡∏ß)
    return grid

# ---------------- 5Ô∏è‚É£ ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏≠‡πà‡∏≤‡∏ô‡πÄ‡∏ü‡∏£‡∏°‡∏à‡∏≤‡∏Å‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥ YOLOP + BEV -----------------
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        print("üöÄ ‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß!")
        break

    try:
        # ‚úÖ ‡πÅ‡∏Å‡πâ Distortion
        undistorted_frame = cv2.undistort(frame, mtxL, distL)

        # ‚úÖ Resize ‡∏†‡∏≤‡∏û‡πÉ‡∏´‡πâ‡∏û‡∏≠‡∏î‡∏µ‡∏Å‡∏±‡∏ö YOLOP
        frame_resized = cv2.resize(undistorted_frame, (640, 640))
        input_tensor = transform(frame_resized).unsqueeze(0).to(device)

        # ‚úÖ ‡∏ó‡∏≥ Object Detection & Lane Detection ‡∏î‡πâ‡∏ß‡∏¢ YOLOP
        with torch.no_grad():
            det_out, da_seg_out, ll_seg_out = model(input_tensor)

        # ‚úÖ ‡πÉ‡∏ä‡πâ argmax ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏û‡∏∑‡πâ‡∏ô‡∏ó‡∏µ‡πà‡∏ó‡∏µ‡πà‡∏Ç‡∏±‡∏ö‡πÑ‡∏î‡πâ (‡∏¢‡πâ‡∏≤‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å GPU ‚Üí CPU ‡∏Å‡πà‡∏≠‡∏ô‡πÉ‡∏ä‡πâ NumPy)
        da_seg_out = da_seg_out.sigmoid().cpu().numpy()
        ll_seg_out = ll_seg_out.sigmoid().cpu().numpy()

        da_seg_out = np.argmax(da_seg_out, axis=1).squeeze(0)
        ll_seg_out = np.argmax(ll_seg_out, axis=1).squeeze(0)

        # ‚úÖ Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ Drivable Area
        print(f"Drivable Area Unique Values: {np.unique(da_seg_out)}")
        print(f"Lane Line Unique Values: {np.unique(ll_seg_out)}")

        # ‚úÖ ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏• YOLOP Front View
        img_det = show_seg_result(frame_resized, (da_seg_out, ll_seg_out), index=0, epoch=0, is_demo=True)
        cv2.imshow("Front View (YOLOP)", img_det)

        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á Drivable Area ‡πÄ‡∏õ‡πá‡∏ô BEV
        bev_drivable_area = cv2.warpPerspective(da_seg_out.astype(np.uint8) * 255, H, (1280, 720))

        # ‚úÖ Debug: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ñ‡πà‡∏≤ BEV
        print(f"BEV Min: {bev_drivable_area.min()}, Max: {bev_drivable_area.max()}")

        # ‚úÖ ‡∏õ‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ô BEV ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏µ‡∏î‡∏≥‡∏•‡πâ‡∏ß‡∏ô
        if bev_drivable_area.max() > 0:
            bev_drivable_area = cv2.normalize(bev_drivable_area, None, 0, 255, cv2.NORM_MINMAX)
            bev_drivable_area = bev_drivable_area.astype(np.uint8)

        cv2.imshow("Bird's Eye View (BEV)", bev_drivable_area)

        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á BEV ‡πÄ‡∏õ‡πá‡∏ô Occupancy Grid
        occupancy_grid = create_occupancy_grid(bev_drivable_area)

        # ‚úÖ ‡πÅ‡∏õ‡∏•‡∏á Grid ‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏û‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
        occupancy_grid_vis = cv2.cvtColor(occupancy_grid * 255, cv2.COLOR_GRAY2BGR)
        cv2.imshow("Occupancy Grid Map", occupancy_grid_vis)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    except Exception as e:
        print(f"‚ö†Ô∏è Error: {e}")
        break

# ---------------- 6Ô∏è‚É£ ‡∏õ‡∏¥‡∏î‡∏ß‡∏¥‡∏î‡∏µ‡πÇ‡∏≠ -----------------
cap.release()
cv2.destroyAllWindows()
